{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.microsoft.com/en-us/learn/modules/train-local-model-with-azure-mls/6-train-model-using-experiment-service\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core import Workspace,Experiment,Run\n",
    "import os\n",
    "\n",
    "# Step 1: name the cluster and set the minimal and maximal number of nodes \n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpucluster\")\n",
    "min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 3)\n",
    "\n",
    "# Step 2: choose environment variables \n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "provisioning_config = AmlCompute.provisioning_configuration(\n",
    "    vm_size = vm_size, min_nodes = min_nodes, max_nodes = max_nodes)\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# create the cluster\n",
    "compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 4 files\n",
      "Uploading ./data_mnist/test-images.gz\n",
      "Uploading ./data_mnist/test-labels.gz\n",
      "Uploading ./data_mnist/train-images.gz\n",
      "Uploading ./data_mnist/train-labels.gz\n",
      "Uploaded ./data_mnist/train-labels.gz, 1 files out of an estimated total of 4\n",
      "Uploaded ./data_mnist/test-labels.gz, 2 files out of an estimated total of 4\n",
      "Uploaded ./data_mnist/test-images.gz, 3 files out of an estimated total of 4\n",
      "Uploaded ./data_mnist/train-images.gz, 4 files out of an estimated total of 4\n",
      "Uploaded 4 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_2e6c0a7ccfd34f0c93cde177b7853be9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload data by using get_default_datastore()\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./data_mnist', target_path='mnist', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create the folder\n",
    "folder_training_script = './trial_model_mnist'\n",
    "os.makedirs(folder_training_script, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./trial_model_mnist/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_training_script/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import gzip\n",
    "import struct\n",
    "\n",
    "# load compressed MNIST gz files and return numpy arrays\n",
    "def load_data(filename, label=False):\n",
    "    with gzip.open(filename) as gz:\n",
    "        struct.unpack('I', gz.read(4))\n",
    "        n_items = struct.unpack('>I', gz.read(4))\n",
    "        if not label:\n",
    "            n_rows = struct.unpack('>I', gz.read(4))[0]\n",
    "            n_cols = struct.unpack('>I', gz.read(4))[0]\n",
    "            res = np.frombuffer(gz.read(n_items[0] * n_rows * n_cols), dtype=np.uint8)\n",
    "            res = res.reshape(n_items[0], n_rows * n_cols)\n",
    "        else:\n",
    "            res = np.frombuffer(gz.read(n_items[0]), dtype=np.uint8)\n",
    "            res = res.reshape(n_items[0], 1)\n",
    "    return res\n",
    "\n",
    "# create three parameters, the location of the data files, and the maximun value of k and the interval\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "parser.add_argument('--kmax', type=int, dest='kmax', default=15, help='max k value')\n",
    "parser.add_argument('--kinterval', type=int, dest='kinterval', default=2, help='k interval')\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_folder = os.path.join(args.data_folder, 'mnist')\n",
    "print('Data folder:', data_folder)\n",
    "\n",
    "# load the train and test set into numpy arrays\n",
    "X_train = load_data(os.path.join(data_folder, 'train-images.gz'), False) / 255.0\n",
    "X_test = load_data(os.path.join(data_folder, 'test-images.gz'), False) / 255.0\n",
    "\n",
    "# Print variable set dimension\n",
    "print(X_train.shape, X_test.shape, sep = '\\n')\n",
    "\n",
    "y_train = load_data(os.path.join(data_folder, 'train-labels.gz'), True).reshape(-1)\n",
    "y_test = load_data(os.path.join(data_folder, 'test-labels.gz'), True).reshape(-1)\n",
    "\n",
    "# Print the response variable dimension\n",
    "print( y_train.shape, y_test.shape, sep = '\\n')\n",
    "\n",
    "# Get hold of the current run\n",
    "run = Run.get_context()\n",
    "\n",
    "print('Train kNN models with k equals to', range(1, args.kmax, args.kinterval))\n",
    "\n",
    "# Generate a wide range of k and find the best models.  Also create a list to store the evaluation result for each value of k\n",
    "kVals = range(1, args.kmax,args.kinterval)\n",
    "evaluation = []\n",
    "\n",
    "# loop over the models with different parameters to find the one with the lowest error rate\n",
    "for k in kVals:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # use the test dataset for evaluation and append the result to the evaluation list\n",
    "    score = model.score(X_test, y_test)\n",
    "    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "    evaluation.append(score)\n",
    "\n",
    "# Find the value of k with the best performance\n",
    "i = int(np.argmax(evaluation))\n",
    "print(\"k = %d with best performance with %.2f%% accuracy given current testset\" % (kVals[i], evaluation[i] * 100))\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "\n",
    "run.log('Best_k', kVals[i])\n",
    "run.log('accuracy', evaluation[i])\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "# Save the model as a pickle file in the outputs folder of the experiment workspace. The pickle file is used to deploy the \n",
    "# model.  The file saved in the outputs folder automatically uploads into the experiment record\n",
    "joblib.dump(value = model, filename = 'outputs/knn_mnist_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "    '--kmax': 5,\n",
    "    '--kinterval': 2\n",
    "}\n",
    "\n",
    "# Import the Scikit-learn package \n",
    "est = Estimator(source_directory=folder_training_script,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='train.py',\n",
    "                conda_packages=['scikit-learn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>my-first-experiment</td><td>my-first-experiment_1565405753_f0741b5d</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/165934ca-a3be-4df3-842b-332997fcecd9/resourceGroups/myresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/llachmanmlworkspace/experiments/my-first-experiment/runs/my-first-experiment_1565405753_f0741b5d\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: my-first-experiment,\n",
       "Id: my-first-experiment_1565405753_f0741b5d,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "# Create an experiment\n",
    "experiment = Experiment(workspace = ws, name = \"my-first-experiment\")\n",
    "\n",
    "run = experiment.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e36e0c3cd294d919cbfd2f21c630fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# monitor the run\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "#get the result\n",
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
